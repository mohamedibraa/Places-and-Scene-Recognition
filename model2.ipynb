{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import cv2\n#from imutils import paths\nfrom tqdm import tqdm\nimport os\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport tensorflow as tf\n!pip install tflearn\nimport tflearn\nfrom tflearn.layers.conv import conv_2d, max_pool_2d,avg_pool_2d\nfrom tflearn.layers.core import input_data, dropout, fully_connected,flatten\nfrom tflearn.layers.estimator import regression\n#from google.colab import drive\n#drive.mount('/content/drive')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-29T03:04:31.409625Z","iopub.execute_input":"2021-12-29T03:04:31.410101Z","iopub.status.idle":"2021-12-29T03:04:48.368615Z","shell.execute_reply.started":"2021-12-29T03:04:31.410004Z","shell.execute_reply":"2021-12-29T03:04:48.367804Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"trainfile=pd.read_csv('../input/ci-sc22-places-and-scene-recognition/train.csv') #share plz ci dataset in your drive from link\ntrainfile=np.array(trainfile)\nx=trainfile[:,0] # namephoto\ny=trainfile[:,1] # label\nprint(x[0])","metadata":{"execution":{"iopub.status.busy":"2021-12-29T03:04:48.371467Z","iopub.execute_input":"2021-12-29T03:04:48.371908Z","iopub.status.idle":"2021-12-29T03:04:48.400788Z","shell.execute_reply.started":"2021-12-29T03:04:48.371865Z","shell.execute_reply":"2021-12-29T03:04:48.400078Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"TRAIN_DIR='../input/ci-sc22-places-and-scene-recognition/train_images/train_images'\nIMG_SIZE = 150\nLR = 0.001\nMODEL_NAME = 'cnn'\ntraining_data = []\n\ndef create_train_data():\n    #i=0\n    for img in tqdm(os.listdir(TRAIN_DIR)):\n        path = os.path.join(TRAIN_DIR, img)\n        #print(path)\n        imagename=path.split('/')[-1] #123.gpj\n        #print(imagename)\n        try:\n           index=np.where(x==imagename)[0][0]\n        except:\n         continue\n        s=np.array([0, 0, 0, 0, 0, 0])\n        s[y[index]]=1\n        #print(s)\n        img_data = cv2.imread(path)\n        img_data = cv2.resize(img_data, (IMG_SIZE, IMG_SIZE))\n        training_data.append([np.array(img_data),s]) #x.gpg,[0,0,0,0,0,1]\n        #i=i+1\n        #if i == 3 :\n         # break\n    np.save('train_data.npy', training_data)\n    return training_data","metadata":{"execution":{"iopub.status.busy":"2021-12-29T03:04:48.403275Z","iopub.execute_input":"2021-12-29T03:04:48.403471Z","iopub.status.idle":"2021-12-29T03:04:48.410876Z","shell.execute_reply.started":"2021-12-29T03:04:48.403447Z","shell.execute_reply":"2021-12-29T03:04:48.410124Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"if (os.path.exists('train_data.npy')): # If you have already created the dataset:\n    train_data =np.load('train_data.npy',allow_pickle=True)\n    print('exist')\nelse: # If dataset is not created:\n    train_data = create_train_data()","metadata":{"execution":{"iopub.status.busy":"2021-12-29T03:04:48.412873Z","iopub.execute_input":"2021-12-29T03:04:48.413399Z","iopub.status.idle":"2021-12-29T03:06:22.440748Z","shell.execute_reply.started":"2021-12-29T03:04:48.413355Z","shell.execute_reply":"2021-12-29T03:06:22.439949Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#plt.imshow(np.array(training_data[2][0]).reshape(50,50))\n#plt.show()\nprint(len(train_data))","metadata":{"execution":{"iopub.status.busy":"2021-12-29T03:06:22.442131Z","iopub.execute_input":"2021-12-29T03:06:22.442416Z","iopub.status.idle":"2021-12-29T03:06:22.446870Z","shell.execute_reply.started":"2021-12-29T03:06:22.442378Z","shell.execute_reply":"2021-12-29T03:06:22.446175Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train = train_data\n\nX_train = np.array([i[0] for i in train]).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\ny_train = [i[1] for i in train]\nprint(X_train.shape)\n\nx = input_data(shape=[None, IMG_SIZE, IMG_SIZE, 3], name='input')\n\nx = tflearn.conv_2d(x, 128, 3, activation='relu', scope='conv1_1')#add\nx = tflearn.conv_2d(x, 128, 3, activation='relu', scope='conv1_2')#add\nx = tflearn.avg_pool_2d(x, 6, strides=2, name='maxpool1')#max\nx = tflearn.conv_2d(x, 128, 3, activation='relu', scope='conv1_3')#add\nx = tflearn.avg_pool_2d(x, 6, strides=2, name='maxpool2')#max\n\nx = tflearn.conv_2d(x, 128, 3, activation='relu', scope='conv2_1')\nx = tflearn.avg_pool_2d(x, 6, strides=2, name='maxpool3')#max\nx = tflearn.conv_2d(x, 128, 3, activation='relu', scope='conv2_2')\nx = tflearn.avg_pool_2d(x, 6, strides=2, name='maxpool4')#max\n\nx = tflearn.conv_2d(x, 256, 3, activation='relu', scope='conv3_1')\nx = tflearn.conv_2d(x, 256, 3, activation='relu', scope='conv3_2')\n\nx = tflearn.avg_pool_2d(x, 6, strides=2, name='maxpool5')#max\n\nx = dropout(x, 0.25)\nx = tflearn.conv_2d(x, 512, 3, activation='relu', scope='conv4_1')\nx = tflearn.avg_pool_2d(x, 6, strides=2, name='maxpool6')#max\nx = tflearn.conv_2d(x, 512, 3, activation='relu', scope='conv4_2')\nx = tflearn.avg_pool_2d(x, 6, strides=2, name='maxpool7')#max\nx = tflearn.conv_2d(x, 512, 3, activation='relu', scope='conv4_3')\nx = tflearn.avg_pool_2d(x, 6, strides=2, name='maxpool8')#max\nx = tflearn.conv_2d(x, 512, 3, activation='relu', scope='conv4_4')#add\nx = tflearn.avg_pool_2d(x, 6, strides=2, name='maxpool9')#max\n\n\nx = conv_2d(x, 1024, 6, activation='relu')\nx = avg_pool_2d(x, 6,strides=2, name='maxpool10')\nx = conv_2d(x, 1024, 6, activation='relu')\nx = avg_pool_2d(x, 6)\nx = avg_pool_2d(x, 6,strides=2, name='maxpool11')\n\nx = tflearn.dropout(x, 0.25, name='dropout2')\nx = flatten(x)\nx = tflearn.fully_connected(x, 4096, activation='relu', scope='fc6')\nx = tflearn.fully_connected(x, 4096, activation='relu', scope='fc7')\nx = tflearn.fully_connected(x, 1000, activation='relu', scope='fc8')\nx = tflearn.fully_connected(x, 6, activation='softmax', scope='fc9')\n\nnetwork = regression(x, optimizer='rmsprop',\n                     loss='categorical_crossentropy',\n                     learning_rate=0.0001)\n\n# Training\nmodel = tflearn.DNN(network, checkpoint_path='model_vgg',\n                    max_checkpoints=1, tensorboard_verbose=0)\n\nif (os.path.exists('model.tfl.meta')):\n    model.load('./model.tfl')\nelse:\n    model.fit(X_train, y_train, n_epoch=100, shuffle=True,\n          show_metric=True, batch_size=32, snapshot_step=500,\n          snapshot_epoch=False, run_id='vgg')\n\n    model.save('model.tfl')","metadata":{"execution":{"iopub.status.busy":"2021-12-29T03:06:22.448087Z","iopub.execute_input":"2021-12-29T03:06:22.448511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TEST_DIR = '../input/ci-sc22-places-and-scene-recognition/test_images/test_images'\nimagename=[]\nindexmax=[]\n#for imgpath in tqdm(os.listdir(TRAIN_DIR)):\nfor img in tqdm(os.listdir(TEST_DIR)):\n    path = os.path.join(TEST_DIR, img)\n    img_data = cv2.imread(path)\n    img_data = cv2.resize(img_data, (IMG_SIZE, IMG_SIZE))\n    img_data = img_data.reshape(IMG_SIZE, IMG_SIZE, 3)\n    x=path.split('/')[-1]\n    try:        \n        z=x.index(\"(\")\n        continue \n    except:\n        imagename.append(x) \n        prediction = model.predict([img_data])[0]\n        pred=np.array(prediction)\n        maxval= max(prediction)\n        indexmax.append(np.where(pred==maxval)[0][0])\n     \n     \n        \nmy_submission = pd.DataFrame({'Image_name': imagename, 'Label': indexmax})\nmy_submission.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}