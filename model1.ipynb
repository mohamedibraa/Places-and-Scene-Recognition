{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import cv2\n#from imutils import paths\nfrom tqdm import tqdm\nimport os\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport tensorflow as tf\n!pip install tflearn\nimport tflearn\nfrom tflearn.layers.conv import conv_2d, max_pool_2d,batch_normalization,avg_pool_2d\nfrom tflearn.layers.core import input_data, dropout, fully_connected,flatten\nfrom tflearn.layers.estimator import regression\n#from google.colab import drive\n#drive.mount('/content/drive')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainfile=pd.read_csv('../input/ci-sc22-places-and-scene-recognition/train.csv') #share plz ci dataset in your drive from link\ntrainfile=np.array(trainfile)\nx=trainfile[:,0] # namephoto\ny=trainfile[:,1] # label\nprint(x[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRAIN_DIR='../input/ci-sc22-places-and-scene-recognition/train_images/train_images'\nIMG_SIZE = 150\nLR = 0.001\nMODEL_NAME = 'cnn'\ntraining_data = []\n\ndef create_train_data():\n    #i=0\n    for img in tqdm(os.listdir(TRAIN_DIR)):\n        path = os.path.join(TRAIN_DIR, img)\n        #print(path)\n        imagename=path.split('/')[-1] #123.gpj\n        #print(imagename)\n        try:\n           index=np.where(x==imagename)[0][0]\n        except:\n         continue\n        s=np.array([0, 0, 0, 0, 0, 0])\n        s[y[index]]=1\n        #print(s)\n        img_data = cv2.imread(path)\n        img_data = cv2.resize(img_data, (IMG_SIZE, IMG_SIZE))\n        training_data.append([np.array(img_data),s]) #x.gpg,[0,0,0,0,0,1]\n        #i=i+1\n        #if i == 3 :\n         # break\n    np.save('train_data.npy', training_data)\n    return training_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if (os.path.exists('train_data.npy')): # If you have already created the dataset:\n    train_data =np.load('train_data.npy',allow_pickle=True)\n    print('exist')\nelse: # If dataset is not created:\n    train_data = create_train_data()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plt.imshow(np.array(training_data[2][0]).reshape(50,50))\n#plt.show()\nprint(len(train_data))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train_data\n\nX_train = np.array([i[0] for i in train]).reshape(-1, IMG_SIZE, IMG_SIZE, 3)\ny_train = [i[1] for i in train]\nprint(X_train.shape)\n\nconv_input = input_data(shape=[None, IMG_SIZE, IMG_SIZE, 3], name='input')\nmodel = conv_2d(conv_input, 128, 3, activation='relu')\nmodel = conv_2d(model, 128, 3, activation='relu')\nmodel = conv_2d(model, 128, 3, activation='relu')\nmodel = avg_pool_2d(model, 6)\n\nmodel = conv_2d(model, 1024, 6, activation='relu')\nmodel = avg_pool_2d(model, 6)\n\nmodel = dropout(model, 0.25)\n\nmodel = conv_2d(model, 1024, 6, activation='relu')\nmodel = avg_pool_2d(model, 6)\n\nconvnet = dropout(model, 0.25)\n\n\nmodel = flatten(convnet)\nmodel = fully_connected(model, 128, activation='relu')\nmodel = fully_connected(model, 256, activation='relu')\nmodel = fully_connected(model, 6, activation='softmax')\n\n\n\nmodel = regression(model, optimizer='adam', learning_rate=1e-3,loss='categorical_crossentropy', name='targets')\nmodel = tflearn.DNN(model, tensorboard_dir='log')\n\n\nif (os.path.exists('model.tfl.meta')):\n    model.load('./model.tfl')\nelse:\n    model.fit(X_train, y_train, n_epoch=25,validation_set=0.1, shuffle=True,\n          show_metric=True, snapshot_step=500,\n          snapshot_epoch=False, run_id=MODEL_NAME)\n\n    model.save('model.tfl')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TEST_DIR = '../input/ci-sc22-places-and-scene-recognition/test_images/test_images'\n#import zipfile #plz upload test_images folder in colab as zip file\n#from zipfile import *\n#zip_ref = zipfile.ZipFile('test_images.zip', 'r') \n#zip_ref.extractall('/tmp') \n#zip_ref.close()\n#TRAIN_DIR = '/tmp/test_images/'\n\nimagename=[]\nindexmax=[]\n#for imgpath in tqdm(os.listdir(TRAIN_DIR)):\nfor img in tqdm(os.listdir(TEST_DIR)):\n    path = os.path.join(TEST_DIR, img)\n    img_data = cv2.imread(path)\n    img_data = cv2.resize(img_data, (IMG_SIZE, IMG_SIZE))\n    img_data = img_data.reshape(IMG_SIZE, IMG_SIZE, 3)\n    x=path.split('/')[-1]\n    try:        \n        z=x.index(\"(\")\n        continue \n    except:\n        imagename.append(x) \n        prediction = model.predict([img_data])[0]\n        pred=np.array(prediction)\n        maxval= max(prediction)\n        indexmax.append(np.where(pred==maxval)[0][0])\n     \n     \n        \n\nmy_submission = pd.DataFrame({'Image_name': imagename, 'Label': indexmax})\nmy_submission.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}